{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "    <img src=\"./img/python-stats.webp\" alt=\"Logo\" width=\"100\" style=\"margin-right: 10px;\"/> \n",
    "    <h1 style=\"margin: 0;\">Arboles de decision</h1>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "**Autor:** Cristiam Loaiza  \n",
    "**Fecha:** 20 de octubre de 2024  \n",
    "**Propósito:** Análisis de Datos usando Python y Herramientas Avanzadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los árboles de decisión son modelos predictivos basados en reglas binarias (sí/no) que permiten clasificar las observaciones según sus atributos, facilitando así la predicción del valor de la variable objetivo.\n",
    "\n",
    "En muchos métodos predictivos, se generan modelos globales en los que una sola ecuación se aplica a todo el conjunto de datos. Sin embargo, cuando se trabaja con múltiples predictores que interactúan de manera compleja y no lineal, resulta complicado encontrar un modelo global que capture adecuadamente estas relaciones. Los métodos estadísticos y de machine learning basados en árboles pertenecen a un conjunto de técnicas supervisadas no paramétricas que dividen el espacio de los predictores en regiones más simples, donde es más fácil gestionar estas interacciones. Esta capacidad de segmentar el espacio es una de las principales fortalezas de los árboles de decisión.\n",
    "\n",
    "Gracias a su versatilidad y efectividad en diversos problemas, los métodos basados en árboles se han posicionado como herramientas clave en el ámbito predictivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ventajas\n",
    "\n",
    "- Los árboles son fáciles de interpretar aun cuando las relaciones entre predictores son complejas.\n",
    "- Los modelos basados en un solo árbol (no es el caso de random forest o boosting) se pueden representar gráficamente incluso cuando el número de predictores es mayor a 3.\n",
    "- Los árboles pueden, en teoría, manejar tanto predictores numéricos como categóricos sin necesidad de crear variables dummy o aplicar one-hot encoding. En la práctica, esto depende de la implementación del algoritmo en cada librería.\n",
    "- Al ser métodos no paramétricos, no requieren que se cumpla ninguna distribución específica.\n",
    "- Generalmente necesitan menos limpieza y preprocesamiento de datos en comparación con otros métodos de aprendizaje estadístico (por ejemplo, no requieren estandarización).\n",
    "- No son muy influenciados por valores atípicos (outliers).\n",
    "- Si algún valor de un predictor no está disponible para una observación, es posible realizar una predicción utilizando las observaciones en el último nodo alcanzado, aunque la precisión pueda reducirse.\n",
    "- Son muy útiles para la exploración de datos, permitiendo identificar rápidamente las variables (predictores) más importantes.\n",
    "- Pueden seleccionar predictores de manera automática.\n",
    "- Son aplicables tanto a problemas de regresión como de clasificación.\n",
    "\n",
    "### Desventajas\n",
    "\n",
    "- La capacidad predictiva de los modelos basados en un único árbol es considerablemente inferior a la de otros modelos, debido a su tendencia al overfitting y alta varianza. Sin embargo, técnicas más avanzadas como bagging, random forest y boosting abordan y mejoran este problema.\n",
    "- Son sensibles a datos de entrenamiento desbalanceados, donde una clase domina sobre las demás.\n",
    "- Al trabajar con predictores continuos, pierden parte de la información al categorizarlos durante la división de los nodos.\n",
    "- La construcción de las ramificaciones de los árboles se basa en el algoritmo de *recursive binary splitting*, que evalúa las posibles divisiones de cada predictor según una medida determinada (RSS, Gini, entropía, etc.). Los predictores continuos, por azar, tienen mayor probabilidad de contener puntos de corte óptimos, lo que puede favorecerlos en la construcción del árbol.\n",
    "- No son capaces de extrapolar fuera del rango de valores de los predictores presentes en los datos de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
